{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ReadingData.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kreshuklab/teaching-dl-course-2019/blob/master/Webinars/exercise1/ReadingData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BDW5sY-dBnC",
        "colab_type": "text"
      },
      "source": [
        "# Reading and saving data for a classification model\n",
        "In this notebook, we first will read images and their corresponding labels and then will wrap and save them in a single file on disk (or google drive). It helps us a lot later to avoid reading so much data each time when we are working with our models.\n",
        "We will use the python pickle module to wrap images in a single file. Any object in Python can be pickled so that it can be saved on disk. \n",
        "Pickling is a way to convert a python object (list, dict, etc.) into a character stream. The idea is that this character stream contains all the information necessary to reconstruct the object in another python script."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2QTJEh7bgal",
        "colab_type": "text"
      },
      "source": [
        "# **Import necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnStabZOSK0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np   # Package for scientific computing\n",
        "import matplotlib.pyplot as plt # 2D plotting library\n",
        "import os     # Using operating system\n",
        "# NOTE: in the tutorials we used cv2 for reading images and resizing.\n",
        "# we replaced this with imageio.imread and skimage.transform.resize\n",
        "# because opencv can cause some dependency issues\n",
        "#from imageio import imread\n",
        "#from skimage.transform import resize\n",
        "import cv2    # Computer vision and machine learning software library\n",
        "from tqdm import tqdm   # Progress bar library\n",
        "import random  # Generating Random Numbers\n",
        "import pickle # Serializing and de-serializing a Python object structure\n",
        "from os.path import join as pj # for path ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIS7BobWfDEK",
        "colab_type": "text"
      },
      "source": [
        "# **Make a connection between colab and your google drive Where your data are saved.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY_WCus6Vy4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "root = '/content/gdrive/'\n",
        "drive.mount( root )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKiPEN9K3L3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create permanent directory in gdrive\n",
        "cifar_dir_path = r'/My Drive/drive_ml/2020_ml_school/02_cifar/'\n",
        "os.makedirs(root+cifar_dir_path, exist_ok=True)\n",
        "os.listdir(root+cifar_dir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K-UfXaQbvZX",
        "colab_type": "text"
      },
      "source": [
        "# **Reading and saving data** \n",
        "What we need is a training data directory (and/or validation data directory)  containing one subdirectory per image class, filled with images. For example: \n",
        "\n",
        "```\n",
        "Animals/\n",
        "    train/\n",
        "        dogs/\n",
        "            dog001.jpg\n",
        "            dog002.jpg\n",
        "            ...\n",
        "        cats/\n",
        "            cat001.jpg\n",
        "            cat002.jpg\n",
        "            ...\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--upd4Y4znu-",
        "colab_type": "text"
      },
      "source": [
        "If you don't have your own data now, you could use the [cifar10](https://www.cs.toronto.edu/~kriz/cifar.html). For this you would have to run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbPhLihUz5g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install cifar2png\n",
        "!cifar2png cifar10 cifar10 #here non-persistent directory will be used to download data (it is first parameter of cifar2png binary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MkRv0jlSQAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DATADIR = cifar_dir_path   # You have to replace the directory of you images instead of \"PathToYourDirectory\".\n",
        "                                                        # For example \"/content/gdrive/My Drive/Animals/train\"\n",
        "DATADIR = \"cifar10/train\"     # for people working on cifar the data is stored locally\n",
        "\n",
        "CATEGORIES = os.listdir(DATADIR)\n",
        "print(CATEGORIES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9qrfUw9ZFuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = []\n",
        "IMG_SIZE_H=\"size\" # you need to set up a numerical value here. Useful to resize to normalize data size\n",
        "IMG_SIZE_W=\"size\" # you need to set up a numerical value here. Useful to resize to normalize data size\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:  # do plants and weeds\n",
        "\n",
        "        path = os.path.join(DATADIR,category)  # create path to the labels\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=plants 1=weeds\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image per plants and weeds\n",
        "        \n",
        "            img_array = cv2.imread(os.path.join(path,img))  # convert to array \n",
        "            new_array = cv2.resize(img_array, (IMG_SIZE_H, IMG_SIZE_W))  # resize to normalize data size\n",
        "            training_data.append([new_array, class_num])  # add this to our training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqQCG_kabahR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_training_data()  # Calling the function for reading images and labels\n",
        "print(len(training_data)) # Printing the size of the database"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--na-6HMb9Lf",
        "colab_type": "text"
      },
      "source": [
        "# **Preparation of data for deeplearning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgbO6BszcCM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.shuffle(training_data)   # Shuffling data \n",
        "X = []  # An Array for images\n",
        "y = []  # An Array for labels\n",
        "\n",
        "for features,label in training_data:   # Seperation of iamegs and labels\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "print(np.array(X).shape) # Print the size of the database"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6eNye7Ecl-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(X).reshape(-1, IMG_SIZE_H, IMG_SIZE_W, 3)  # Reshape data in a form that is suitable for keras\n",
        "print(X.shape) # Print the size of the database"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIjKMSy4ydIR",
        "colab_type": "text"
      },
      "source": [
        "# **Visualisation and Saving**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgM21lmdya9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot 3 images as gray scale\n",
        "plt.subplot(131)\n",
        "plt.imshow(X[0,:,:,0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(132)\n",
        "plt.imshow(X[1,:,:,0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(133)\n",
        "plt.imshow(X[1,:,:,1], cmap=plt.get_cmap('gray')) #CIFAR data contains 3 channels, here we display 2nd channel for 1st image\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlNKV8fscwlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fn_X = \"X.pickle\"\n",
        "fn_Y = \"Y.pickle\"\n",
        "\n",
        "pickle_out = open(root+cifar_dir_path+fn_X,\"wb\") # wrapping up images # You have to replace the directory of you images instead of \"PathToSaveTheFile\".\n",
        "                                                        # For example \"/content/gdrive/My Drive/MyFolder/X.pickle\"\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(root+cifar_dir_path+fn_Y,\"wb\") # wrapping up labels # You have to replace the directory of you images instead of \"PathToSaveTheFile\".\n",
        "                                                        # For example \"/content/gdrive/My Drive/MyFolder/y.pickle\"\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}