{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist_DL_Example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kreshuklab/teaching-dl-course-2019/blob/master/Webinars/exercise2/Mnist_DL_Example_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LwMErUE4nqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNk9xoejq0Gu",
        "colab_type": "text"
      },
      "source": [
        "# **Make your fist experience with Tensorflow-Keras**\n",
        "Our goal is to construct and train an artificial neural network on thousands of images of handwritten digits so that it may successfully identify others when presented. The data that will be incorporated is the MNIST database which contains 60,000 images for training and 10,000 test images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUaYe-8hrq0a",
        "colab_type": "text"
      },
      "source": [
        "## Loading Training and Validation Data\n",
        "\n",
        "The MNIST dataset is conveniently bundled within Keras, and we can easily analyze some of its features in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyugMSBellom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_val, y_val) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEFL5miLsJAO",
        "colab_type": "text"
      },
      "source": [
        "# **Importing necessary Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbe9-7F0llo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential # Model type to be used\n",
        "from keras.layers import Dense, Activation, Dropout# Make Fully connected (FC) layers\n",
        "from keras.utils import np_utils  # NumPy related tools\n",
        "from keras.callbacks import TensorBoard  #Visulization of Accuracy and loss\n",
        "!pip install tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random                        # for generating random numbers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j94bah8itXXQ",
        "colab_type": "text"
      },
      "source": [
        "Visualization of some input images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2msmk9kllo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    num = random.randint(0, len(X_train))\n",
        "    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Class {}\".format(y_train[num]))\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_zCqwWUtsQk",
        "colab_type": "text"
      },
      "source": [
        "## Formatting the input data layer\n",
        "\n",
        "Instead of a 28 x 28 matrix, we build our network to accept a 784-length vector. Each image needs to be then reshaped (or flattened) into a vector. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZcXG7IlllpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 784).astype('float32')\n",
        "X_val = X_val.reshape(X_val.shape[0], 784).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train /= 255\n",
        "X_val /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMqOlzCvum99",
        "colab_type": "text"
      },
      "source": [
        "We then modify our classes (unique digits) to be in the one-hot format, i.e."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noBosoMQupvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode outputs\n",
        "Y_train = np_utils.to_categorical(y_train)\n",
        "Y_val = np_utils.to_categorical(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppNdrarWvSEV",
        "colab_type": "text"
      },
      "source": [
        "# Building the simplest fully connected network (FCN) with just one layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytj_eL4zvFDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Sequential model is a linear stack of layers and is very common.\n",
        "model = Sequential([\n",
        "    Dense(10), # It is the output layer and should be equal to the number of desired classes (10 in this case).\n",
        "    Activation('softmax'),\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyJ_BhHrv52F",
        "colab_type": "text"
      },
      "source": [
        "## Compiling the model\n",
        "\n",
        "Keras is built on top of TensorFlow. It allows you to define a *computation graph* in Python, which then compiles and runs efficiently on the CPU or GPU without the overhead of the Python interpreter.\n",
        "\n",
        "When compiling a model, Keras asks you to specify your **loss function** and your **optimizer**. The loss function we'll use here is called *categorical cross-entropy*, and is a loss function well-suited to comparing two probability distributions.\n",
        "\n",
        "Our predictions are probability distributions across the ten different digits (e.g. \"we're 80% confident this image is a 3, 10% sure it's an 8, 5% it's a 2, etc.\"), and the target is a probability distribution with 100% for the correct category, and 0 for everything else. The cross-entropy is a measure of how different your predicted distribution is from the target distribution. [More detail at Wikipedia](https://en.wikipedia.org/wiki/Cross_entropy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_gOe1jFv4dk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICIcOBrR0G3D",
        "colab_type": "text"
      },
      "source": [
        "# **TensorFlow's visualization toolkit**\n",
        "\n",
        "TensorBoard provides the visualization and tooling needed for machine learning experimentation:\n",
        "*   Tracking and visualizing metrics such as loss and accuracy\n",
        "*   Visualizing the model graph (ops and layers)\n",
        "*   Viewing histograms of weights, biases, or other tensors as they change over time\n",
        "*   Projecting embeddings to a lower dimensional space\n",
        "*   Displaying images, text, and audio data\n",
        "*   Profiling TensorFlow programs\n",
        "*   And much more\n",
        "\n",
        "After running the following block, you should click on the generated lik.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsVkxH97llpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9UNb8kfyp9O",
        "colab_type": "text"
      },
      "source": [
        "## Train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBlmYIToyfwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, Y_train, \n",
        "          validation_data=(X_val, Y_val),\n",
        "          epochs=5, batch_size=32,\n",
        "          verbose=1,\n",
        "          callbacks=[TensorBoardColabCallback(tbc)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX5YLXkA1e66",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate Model's Accuracy on Test Data\n",
        "Your test data **Must** be different from the validation data, but in this example, we will use the validation data as the test data as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIaorIub1jw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_val, Y_val)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8zG9fGI35DI",
        "colab_type": "text"
      },
      "source": [
        "### Inspecting the output\n",
        "\n",
        "It's always a good idea to inspect the output and make sure everything looks sane. Here we'll look at some examples it gets right, and some examples it gets wrong."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojQlAkh_36R0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The predict_classes function outputs the highest probability class\n",
        "# according to the trained classifier for each input example.\n",
        "predicted_classes = model.predict_classes(X_val)\n",
        "\n",
        "# Check which items we got right / wrong\n",
        "correct_indices = np.nonzero(predicted_classes == y_val)[0]\n",
        "\n",
        "incorrect_indices = np.nonzero(predicted_classes != y_val)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4coF9cdC4FuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "for i, correct in enumerate(correct_indices[:6]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_val[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_val[correct]))\n",
        "    \n",
        "plt.tight_layout()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAm5wIBo7C1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "for i, incorrect in enumerate(incorrect_indices[:6]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_val[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_val[incorrect]))\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzB25C3M7NBh",
        "colab_type": "text"
      },
      "source": [
        "# **Let's go Deeper**\n",
        "We will add four more layers to our model. We use Droupout in our model to reduce overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6z6Pj5z7mIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropout helps protect the model from memorizing or \"overfitting\" the training data.\n",
        "Pkeep=0.25\n",
        "modelDeepFC = Sequential([\n",
        "    Dense(200, input_shape=(784,)),\n",
        "    Activation('relu'),\n",
        "    Dropout(Pkeep),\n",
        "    Dense(100, input_shape=(200,)),\n",
        "    Activation('relu'),\n",
        "    Dropout(Pkeep),\n",
        "    Dense(60, input_shape=(100,)),\n",
        "    Activation('relu'),\n",
        "    Dropout(Pkeep),\n",
        "    Dense(30, input_shape=(60,)),\n",
        "    Activation('relu'),\n",
        "    Dropout(Pkeep),\n",
        "    Dense(10),\n",
        "    Activation('softmax'),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-xH-kpX_N27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tbcDeepFC=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSaOEmsg-pJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelDeepFC.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelDeepFC.fit(X_train, Y_train, \n",
        "          validation_data=(X_val, Y_val),\n",
        "          epochs=5, batch_size=32,\n",
        "          verbose=1,\n",
        "          callbacks=[TensorBoardColabCallback(tbcDeepFC)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gy_4HN0BWgq",
        "colab_type": "text"
      },
      "source": [
        "The performance of the last model with more layers showed a better performance compare with our first model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_gM34gjBsAW",
        "colab_type": "text"
      },
      "source": [
        "# **Let's go furter with introducing CNN**\n",
        "Before, we built a network that accepts the normalized pixel values of each value and operates soley on those values. What if we could instead feed different features (e.g. curvature, edges) of each image into a network, and have the network learn which features are important for classifying an image?\n",
        "\n",
        "This possible through convolution! Convolution applies kernels (filters) that traverse through each image and generate feature maps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HfNFU_ZCV7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import some additional tools\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnyHx6KdCpDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3_HL1Z5CsMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Again, do some formatting\n",
        "# Except we do not flatten each image into a 784-length vector because we want to perform convolutions first\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') #add an additional dimension to represent the single-channel\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VuttSwGDQdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode outputs\n",
        "Y_train = np_utils.to_categorical(y_train)\n",
        "Y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsVz160NDdwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelCNN = Sequential([\n",
        "    \n",
        "    # Convolution Layer 1\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), # 32 different 3x3 kernels -- so 32 feature maps\n",
        "    MaxPooling2D(pool_size=(2, 2)), # Pool the max values over a 2x2 kernel\n",
        "\n",
        "    # Convolution Layer 2\n",
        "    Conv2D(64, (3, 3), activation='relu'), # 64 different 3x3 kernels \n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Convolution Layer 3\n",
        "    Conv2D(128, (3, 3), activation='relu'), # 128 different 3x3 kernels\n",
        "\n",
        "    Flatten(), # Flatten final 7x7x128 output matrix into a 1024-length vector \n",
        "\n",
        "    # Fully Connected Layer 4\n",
        "    Dense(512), # 512 FCN nodes\n",
        "    Activation('relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(10),\n",
        "    Activation('softmax'),\n",
        "])\n",
        "modelCNN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH9KNpw-FMZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tbcCNN=TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2kzBiLRE3Hw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelCNN.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelCNN.fit(X_train, Y_train, \n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=5, batch_size=32,\n",
        "          verbose=1,\n",
        "          callbacks=[TensorBoardColabCallback(tbcCNN)])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
